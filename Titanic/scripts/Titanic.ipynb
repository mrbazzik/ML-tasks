{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split,StratifiedShuffleSplit,StratifiedKFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import json as js\n",
    "import pickle as pkl\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy  import stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import re\n",
    "import os\n",
    "from sklearn.externals.six import StringIO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reFind(str, x, na):\n",
    "    ar = re.compile(str).findall(x)\n",
    "    if len(ar) ==0:\n",
    "        return na\n",
    "    else:\n",
    "        return ar[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepareData(df, seed):\n",
    "    \n",
    "    print('cleaning features...')\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "\n",
    "    ##-- Cabin --\n",
    "    df['CabinNA'] = df.Cabin.isnull()\n",
    "    df.Cabin = df.Cabin.fillna('U0')\n",
    "\n",
    "    df['CabinFactor'] = pd.factorize(df.Cabin)[0]\n",
    "\n",
    "    df['CabinLetter'] = df.Cabin.map(lambda x: reFind(\"([a-zA-z]+)\", x, ''))\n",
    "    dum = pd.get_dummies(df.CabinLetter,prefix='CabinLetter')\n",
    "    df = pd.concat([df, dum], 1)\n",
    "    df['CabinLetterFactor'] = df.CabinLetter.map({'A':0,\n",
    "                                                  'B':1,\n",
    "                                                  'C':2,\n",
    "                                                  'D':3,\n",
    "                                                  'E':4,\n",
    "                                                  'F':5,\n",
    "                                                  'G':6,\n",
    "                                                  'T':7,\n",
    "                                                  'U':8})\n",
    "    df['CabinLetterBin'] = df.CabinLetter.map({'A':0,\n",
    "                                                  'B':0,\n",
    "                                                  'C':0,\n",
    "                                                  'D':1,\n",
    "                                                  'E':1,\n",
    "                                                  'F':1,\n",
    "                                                  'G':2,\n",
    "                                                  'T':2,\n",
    "                                                  'U':2})\n",
    "    \n",
    "\n",
    "    df['CabinNumber'] = df.Cabin.map(lambda x: reFind(\"([0-9]+)\", x, '0')).astype(int)\n",
    "    ##df['CabinNumberBin'] = df.CabinNumber.map(lambda x: )\n",
    "    ##df['CabinNumberBin'] = pd.qcut(df.CabinNumber,3)\n",
    "    ##df.CabinNumberBin = pd.factorize(df.CabinNumberBin)[0]\n",
    "    \n",
    "    ##-- Embarked --\n",
    "    df.Embarked = df.Embarked.fillna(df.Embarked.mode()[0])\n",
    "\n",
    "    df['EmbarkedFactor'] = pd.factorize(df.Embarked)[0]\n",
    "\n",
    "    dum = pd.get_dummies(df.Embarked,prefix='Embarked')\n",
    "    df = pd.concat([df, dum], 1)\n",
    "    \n",
    "    ##-- Fare --\n",
    "    fare_med = pd.pivot_table(df,values='Fare', index='Pclass', aggfunc='median')\n",
    "    \n",
    "    df.Fare = df[['Fare','Pclass']].apply(lambda x: fare_med[int(x.Pclass)] if pd.isnull(x.Fare) else x.Fare, 1)\n",
    "\n",
    "##    df['FareScaled'] = scaler.fit_transform(df.Fare)\n",
    "    \n",
    "    df['FareBin'] = pd.qcut(df.Fare,5)\n",
    "    df.FareBin = pd.factorize(df.FareBin)[0]\n",
    "    \n",
    "    ##-- Age --\n",
    "    df['AgeNA'] = df.Age.isnull()\n",
    "    \n",
    "    knownAge = df.loc[df.Age.notnull(),:]\n",
    "    unknownAge = df.loc[df.Age.isnull(),:]\n",
    "    dropCol = ['Age','Survived','Cabin','Embarked','Name','Sex','Ticket','CabinLetter','CabinNumber']\n",
    "    x_train = knownAge.drop(dropCol,1)\n",
    "    y_train = knownAge.Age\n",
    "    x_test = unknownAge.drop(dropCol,1)\n",
    "    rfr = RandomForestRegressor(n_estimators=2000, n_jobs=-1, random_state = seed)\n",
    "    rfr.fit(x_train,y_train)\n",
    "    df.loc[unknownAge.index,'Age'] = rfr.predict(x_test)\n",
    "\n",
    "    \n",
    "##    df['AgeScaled'] = scaler.fit_transform(df.Age)\n",
    "\n",
    "    df['AgeBin'] = pd.qcut(df.Age,5)\n",
    "    df.AgeBin = pd.factorize(df.AgeBin)[0]\n",
    "\n",
    "    ##-- Parch --\n",
    "    ##df['ParchBin']=pd.qcut(df.Parch, 3)\n",
    "    ##df.ParchBin = pd.factorize(df.ParchBin)[0]\n",
    "\n",
    "    ##-- Sex --\n",
    "    df.Sex = pd.factorize(df.Sex)[0]\n",
    "\n",
    "    ##-- SibSp --\n",
    "    ##df['SibSpBin']=pd.qcut(df.SibSp, 2)\n",
    "    ##df.SibSpBin = pd.factorize(df.SibSpBin)[0]\n",
    "    \n",
    "\n",
    "    ##-- Name --\n",
    "    df['NameLen'] = df.Name.map(lambda x: len(re.split(' ',x)))\n",
    "\n",
    "    df['Title'] = df.Name.map(lambda x: re.compile(\", (.*?)\\.\").findall(x)[0])\n",
    "    titles={'Master': ['Jonkheer'],\n",
    "            'Miss': ['Ms', 'Mlle'],\n",
    "            'Mrs': ['Mme'],\n",
    "            'Sir': ['Capt','Don','Major','Col'],\n",
    "            'Lady': ['Dona', 'the Countess']}\n",
    "    df['TitleBin']=df.Title\n",
    "    for i in titles:\n",
    "        df.loc[df.Title.isin(titles[i]),'TitleBin'] = i\n",
    "    dum = pd.get_dummies(df.TitleBin, prefix='Title')\n",
    "    df = pd.concat([df,dum],1)\n",
    "    df.TitleBin = pd.factorize(df.TitleBin)[0]\n",
    "\n",
    "    df['Surname'] = df.Name.map(lambda x: re.split(' ',x)[0])\n",
    "    \n",
    "\n",
    "    ##-- Ticket --\n",
    "    df['TicketPrefix'] = df.Ticket.map(lambda x: reFind(\"([a-zA-z\\.\\/]+)\", x, ''))\n",
    "    df['TicketPrefix'] = df.TicketPrefix.map(lambda x: re.sub(\"[\\.\\/]\",'',x))\n",
    "    dum = pd.get_dummies(df.TicketPrefix, prefix='TicketPrefix')\n",
    "    df = pd.concat([df,dum],1)\n",
    "    df.TicketPrefix = pd.factorize(df.TicketPrefix)[0]\n",
    "\n",
    "    df['TicketNumber'] = df.Ticket.map(lambda x: reFind(\"([\\d]+$)\", x, '0')).astype(int)\n",
    "    df['TicketNumberLen'] = df.TicketNumber.map(lambda x: len(str(x))).astype(int)\n",
    "    df['TicketNumberFD'] = df.TicketNumber.map(lambda x: str(x)[0]).astype(int)\n",
    "\n",
    "    df['TicketNumberBin'] = pd.qcut(df.TicketNumber, 10)\n",
    "    df.TicketNumberBin = pd.factorize(df.TicketNumberBin)[0]\n",
    "\n",
    "\n",
    "    ##-- new features --\n",
    "    print('making new features...')\n",
    "    df['FamilySize'] = df.Parch+df.SibSp\n",
    "    \n",
    "    df['FamilyId'] = df[['FamilySize','Surname']].apply(lambda x: x.Surname+str(x.FamilySize),1)\n",
    "    df.FamilyId = pd.factorize(df.FamilyId)[0]\n",
    "\n",
    "##    columns = ['Pclass','Sex','SibSp','Parch','CabinFactor', 'CabinLetterFactor','CabinNumber','EmbarkedFactor','Fare','Age','NameLen','TitleBin','TicketPrefix','TicketNumber','TicketNumberLen','FamilySize','FamilyId']\n",
    "##    for i,iel in enumerate(columns):\n",
    "##        for j,jel in enumerate(columns):\n",
    "##            if i < j:\n",
    "##                df[iel+\"+\"+jel] = df[iel]+df[jel]\n",
    "##            if i <= j:\n",
    "##                df[iel+\"*\"+jel] = df[iel]*df[jel]\n",
    "##            if i != j:\n",
    "##                df[iel+\"/\"+jel] = df[iel]/df[jel].astype(float)\n",
    "##                df[iel+\"-\"+jel] = df[iel]-df[jel]\n",
    "##\n",
    "    ##y = df.Survived\n",
    "##\n",
    "    df = df.drop(['Cabin', 'Embarked', 'Name', 'Ticket', 'CabinLetter', 'Title', 'Surname','PassengerId'],1)\n",
    "##    \n",
    "##    have_null = sp.sum(pd.isnull(df))\n",
    "##    df = df.drop(have_null[have_null>0].index.tolist(),1)\n",
    "##\n",
    "##    have_inf = [k for k in df.columns if sp.sum(sp.isinf(df[k]))>0]\n",
    "##    df = df.drop(have_inf,1)\n",
    "        \n",
    "    ##-- check correlated features --\n",
    "    ##print('deleting correlated features...')\n",
    "##    df_corr = df.corr(method = 'spearman')\n",
    "##    mask = sp.ones(df_corr.columns.size) - sp.eye(df_corr.columns.size)\n",
    "##    df_corr = df_corr*mask\n",
    "##    dels=[]\n",
    "##    for i in df_corr.columns:\n",
    "##        if i in dels:\n",
    "##            continue\n",
    "##        inds = df_corr.loc[abs(df_corr[i])>=0.98,i].index.tolist()\n",
    "##        for ind in inds:\n",
    "##            if ind not in dels:\n",
    "##                dels.append(ind)\n",
    "##    df = df.drop(dels,1)\n",
    "\n",
    "    \n",
    "    ##-- PCA --\n",
    "##    print('making pca...')\n",
    "##    pca=PCA(0.9999999999)\n",
    "##    Xtrans = pca.fit_transform(df)\n",
    "    ##df = pd.concat([df, y],1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Reading settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = js.loads(open('../SETTINGS.json').read())\n",
    "train_path = \"../\"+config[\"TRAIN_DATA_PATH\"]\n",
    "test_path = \"../\"+config[\"TEST_DATA_PATH\"]\n",
    "model_path = \"../\"+config[\"MODEL_PATH\"]\n",
    "seed = int(config[\"SEED\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning features...\n",
      "making new features...\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(train_path+\"/train.csv\")\n",
    "df_test = pd.read_csv(test_path+\"/test.csv\")\n",
    "\n",
    "df_full = pd.concat([df_train,df_test])\n",
    "df_full = df_full.reset_index()\n",
    "df_full = df_full.drop('index',1)\n",
    "\n",
    "\n",
    "df_full = prepareData(df_full, seed)\n",
    "d_train = df_full.loc[df_full.Survived.notnull(),:]\n",
    "\n",
    "x_train = d_train.drop('Survived',1)\n",
    "y_train = d_train.Survived\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "###Simple decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_train = []\n",
    "score_test = []\n",
    "for i in sp.arange(1,51):\n",
    "    dt_cls = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=i, min_samples_leaf=1, \n",
    "                                min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, \n",
    "                                class_weight=None)\n",
    "    dt_cls.fit(x_train, y_train)\n",
    "    score_train.append(dt_cls.score(x_train,y_train))\n",
    "    score_test.append(dt_cls.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(sp.arange(1,51),score_test)\n",
    "plt.plot(sp.arange(1,51),score_train)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
